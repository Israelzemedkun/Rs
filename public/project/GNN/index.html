<!doctype html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: August 11, 2024 --><html lang="en-us" dir="ltr"
      data-wc-theme-default="system">
  
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="generator" content="Hugo Blox Builder 0.2.0" />

  
  












  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="1. Introduction Background Generative Adversarial Networks (GANs) have emerged as a groundbreaking development in the field of machine learning since their introduction by Ian Goodfellow and colleagues in 2014. GANs consist of two competing neural networks, known as the generator and the discriminator, that engage in a dynamic adversarial process." />

  
  <link rel="alternate" hreflang="en-us" href="http://localhost:1313/project/gnn/" />

  
  
  
  
    
    <link rel="stylesheet" href="/css/themes/emerald.min.css" />
  

  
  
    
    <link href="/dist/wc.min.css" rel="stylesheet" />
  

  
  
  

  

  <script>
     
    window.hbb = {
       defaultTheme: document.documentElement.dataset.wcThemeDefault,
       setDarkTheme: () => {
        document.documentElement.classList.add("dark");
        document.documentElement.style.colorScheme = "dark";
      },
       setLightTheme: () => {
        document.documentElement.classList.remove("dark");
        document.documentElement.style.colorScheme = "light";
      }
    }

    console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`);

    if ("wc-color-theme" in localStorage) {
      localStorage.getItem("wc-color-theme") === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
    } else {
      window.hbb.defaultTheme === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      if (window.hbb.defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      }
    }
  </script>

  <script>
    
    document.addEventListener('DOMContentLoaded', function () {
      
      let checkboxes = document.querySelectorAll('li input[type=\'checkbox\'][disabled]');
      checkboxes.forEach(e => {
        e.parentElement.parentElement.classList.add('task-list');
      });

      
      const liNodes = document.querySelectorAll('.task-list li');
      liNodes.forEach(nodes => {
        let textNodes = Array.from(nodes.childNodes).filter(node => node.nodeType === 3 && node.textContent.trim().length > 1);
        if (textNodes.length > 0) {
          const span = document.createElement('label');
          textNodes[0].after(span);  
          span.appendChild(nodes.querySelector('input[type=\'checkbox\']'));
          span.appendChild(textNodes[0]);
        }
      });
    });
  </script>

  
  
  




































  
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="http://localhost:1313/project/gnn/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Academic CV" />
  <meta property="og:url" content="http://localhost:1313/project/gnn/" />
  <meta property="og:title" content="Deep Learning with PyTorch : Generative Adversarial Network | Academic CV" />
  <meta property="og:description" content="1. Introduction Background Generative Adversarial Networks (GANs) have emerged as a groundbreaking development in the field of machine learning since their introduction by Ian Goodfellow and colleagues in 2014. GANs consist of two competing neural networks, known as the generator and the discriminator, that engage in a dynamic adversarial process." /><meta property="og:image" content="http://localhost:1313/project/gnn/featured.png" />
    <meta property="twitter:image" content="http://localhost:1313/project/gnn/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2024-06-27T22:52:51&#43;05:30"
      />
    
    <meta property="article:modified_time" content="2024-06-27T22:52:51&#43;05:30">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/project/gnn/"
  },
  "headline": "Deep Learning with PyTorch : Generative Adversarial Network",
  
  "image": [
    "http://localhost:1313/project/gnn/featured.png"
  ],
  
  "datePublished": "2024-06-27T22:52:51+05:30",
  "dateModified": "2024-06-27T22:52:51+05:30",
  
  "publisher": {
    "@type": "Organization",
    "name": "Academic CV",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "1. Introduction Background Generative Adversarial Networks (GANs) have emerged as a groundbreaking development in the field of machine learning since their introduction by Ian Goodfellow and colleagues in 2014. GANs consist of two competing neural networks, known as the generator and the discriminator, that engage in a dynamic adversarial process."
}
</script>

  

  


  <title>Deep Learning with PyTorch : Generative Adversarial Network | Academic CV</title>

  
  
  
  
  
    
    
  
  
  <style>
    @font-face {
      font-family: 'Inter var';
      font-style: normal;
      font-weight: 100 900;
      font-display: swap;
      src: url(/dist/font/Inter.var.woff2) format(woff2);
    }
  </style>

  

  
  


  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
    
  
  
  







<link type="text/css" rel="stylesheet" href="/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css" integrity="sha256-vnZutBkxehTsdp0hbpd5v&#43;jzc3yA54D0ug2vtXpBpII=" />


<script src="/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js" integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script>


<script>window.hbb.pagefind = {"baseUrl":"/"};</script>

<style>
  html.dark {
    --pagefind-ui-primary: #eeeeee;
    --pagefind-ui-text: #eeeeee;
    --pagefind-ui-background: #152028;
    --pagefind-ui-border: #152028;
    --pagefind-ui-tag: #152028;
  }
</style>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    new PagefindUI({
      element: "#search",
      showSubResults: true,
      baseUrl: window.hbb.pagefind.baseUrl,
      bundlePath: window.hbb.pagefind.baseUrl + "pagefind/",
    });
  });
  document.addEventListener('DOMContentLoaded', () => {
    let element = document.getElementById('search');
    let trigger = document.getElementById('search_toggle');

    if (trigger) {
      trigger.addEventListener('click', () => {
        element.classList.toggle('hidden');
        element.querySelector("input").value = ""
        element.querySelector("input").focus()

        if (!element.classList.contains('hidden')) {
          let clear_trigger = document.querySelector('.pagefind-ui__search-clear');

          if (clear_trigger && !clear_trigger.hasAttribute('listenerOnClick')) {
            clear_trigger.setAttribute('listenerOnClick', 'true');

            clear_trigger.addEventListener('click', () => {
              element.classList.toggle('hidden');
            });
          }
        }

      });
    }
  });
</script>















  
  
  
  
  
  
  
  <script
    defer
    src="/js/hugo-blox-en.min.js"
    integrity=""
  ></script>

  
  








  
    
      
      <script async defer src="https://buttons.github.io/buttons.js"></script>

      
    
  




</head>

  <body class="dark:bg-hb-dark dark:text-white page-wrapper" id="top">
    <div id="page-bg"></div>
    <div class="page-header sticky top-0 z-30">
      
      
      
        
        
        
          <header id="site-header" class="header">
  <nav class="navbar px-3 flex justify-left">
    <div class="order-0 h-100">
      
      <a class="navbar-brand" href="/" title="Academic CV">
        Israel
      </a>
    </div>
    
    <input id="nav-toggle" type="checkbox" class="hidden" />
    <label
      for="nav-toggle"
      class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1">
      <svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20">
        <title>Open Menu</title>
        <path d="M0 3h20v2H0V3z m0 6h20v2H0V9z m0 6h20v2H0V0z"></path>
      </svg>
      <svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20">
        <title>Close Menu</title>
        <polygon
          points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2"
          transform="rotate(45 10 10)"></polygon>
      </svg>
    </label>
    

    
    
    <ul
      id="nav-menu"
      class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left
      ">
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/"
        >Bio</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/experience/"
        >Experience</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/projects/"
        >Projects</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/docs/"
        >Teaching</a
        >
      </li>
      
      
      
    </ul>

    <div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0">

      
      
      
      <button
        aria-label="search"
        class="text-black hover:text-primary  inline-block px-3 text-xl dark:text-white"
        id="search_toggle">
        <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 512 512" fill="currentColor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288z"/></svg>
      </button>
      

      
      
      <div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
            [&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white">
        <button class="theme-toggle mt-1" accesskey="t" title="appearance">
          <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class="dark:hidden">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class=" dark:block [&:not(dark)]:hidden">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      </div>
      

      
      

      
      
    </div>
  </nav>
</header>


<div id="search" class="hidden p-3"></div>


        
      
    </div>
    <div class="page-body  my-10">
      





<div class="mx-auto flex max-w-screen-xl">
  



<aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block">
  
  <div class="px-4 pt-4 lg:hidden">
    
    
  </div>
  <div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]">
    <ul class="flex flex-col gap-1 lg:hidden">
      
      
        <li class="open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/"
    
  >Projects
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/preprint/"
    
  >Mapping Teak Tree Plantations
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900"
    href="/project/gnn/"
    
  >Deep Learning with PyTorch : Generative Adversarial Network
    </a>
  
    <ul class="hb-sidebar-mobile-toc"><li>
              <a
                href="#1-introduction"
                class="hb-docs-link"
              >1. Introduction</a>
            </li>
          <li>
              <a
                href="#2-literature-review"
                class="hb-docs-link"
              >2. Literature Review</a>
            </li>
          <li>
              <a
                href="#3-methodology"
                class="hb-docs-link"
              >3. Methodology</a>
            </li>
          <li>
              <a
                href="#4-experimental-setup"
                class="hb-docs-link"
              >4. Experimental Setup</a>
            </li>
          <li>
              <a
                href="#5-results"
                class="hb-docs-link"
              >5. Results</a>
            </li>
          <li>
              <a
                href="#6-discussion"
                class="hb-docs-link"
              >6. Discussion</a>
            </li>
          <li>
              <a
                href="#7-conclusion"
                class="hb-docs-link"
              >7. Conclusion</a>
            </li>
          <li>
              <a
                href="#8-references"
                class="hb-docs-link"
              >8. References</a>
            </li>
          <li>
              <a
                href="#9-appendices"
                class="hb-docs-link"
              >9. Appendices</a>
            </li>
          </ul>
  
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/streamlit-dashboard/"
    
  >Motor Vehicle Collisions in New York City Dashboard Project
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/gee_jpn/"
    
  >The Impact of COVID 19 Lockdown on Air Quality
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/drops-of-hope/"
    
  >Drops of Hope: Ethiopia&#39;s Water Scarcity Challenge
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/gee_bais/"
    
  >Google Earth Engine Based Approach for Irrigation Scheduling
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/conference-paper/"
    
  >Low-Cost Automated Basketball Score Tracking System
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/"
    
  >Publications
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/preprint/"
    
  >Mapping Teak Tree Plantations
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/conference-paper/"
    
  >Low-Cost Automated Basketball Score Tracking System | Fun Side project
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/projects/"
    
  >Projects
    </a></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/"
    
  >Teaching
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/dbms/"
    
  >DBMS
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a>
              <div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/dbms/introduction-to-database-management-systems/"
    
  >Introduction to Database Management Systems
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/dbms/data-modeling-and-er-model/"
    
  >Data Modeling and ER Model
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/dbms/relational-databases/"
    
  >Relational Databases
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/dbms/structured-query-language/"
    
  >SQL: Structured Query Language
    </a>
              
            </li></ul>
      </div>
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/"
    
  >Remote Sensing and GIS
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a>
              <div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/getting-started/"
    
  >Introduction to Remote Sensing
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/image-visualisaton/"
    
  >Image Visualisations
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/project-structure/"
    
  >Spectra to Indices, and Finding the Right Image
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/configuration/"
    
  >Image Classification
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/classification/"
    
  >Accuracy Assessment
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/sar-in-gee/"
    
  >SAR Data in Google Earth Engine
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/plotting-spectral-response-curves/"
    
  >Plotting Spectral Response Curves
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/docs/guide/reference/"
    
  >Reference
    </a>
              
            </li></ul>
      </div>
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/"
    
  >Blog
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/get-started/"
    
  >ðŸŽ‰ Easily create your own simple yet highly customizable blog
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/second-brain/"
    
  >ðŸ§  Sharpen your thinking with a second brain
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/data-visualization/"
    
  >ðŸ“ˆ Communicate your results effectively with the best data visualizations
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/experience/"
    
  >Experience
    </a></li>
    </ul>

    <div class="max-xl:hidden h-0 w-64 shrink-0"></div></div>

</aside>
  

<nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents">
  











  <div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#1-introduction">1. Introduction</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#background">Background</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#objectives">Objectives</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#research-questions">Research Questions</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#2-literature-review">2. Literature Review</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#review-related-work">Review Related Work</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#identify-gaps">Identify Gaps</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#3-methodology">3. Methodology</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#architecture-and-configuration">Architecture and Configuration</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#data-preparation-and-augmentation">Data Preparation and Augmentation</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#model-architecture">Model Architecture</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#discriminator-network">Discriminator Network</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#generator-network">Generator Network</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#create-loss-function-and-load-optimizer">Create Loss Function and Load Optimizer</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#training-loop">Training Loop</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#4-experimental-setup">4. Experimental Setup</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#environment">Environment</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#parameters">Parameters</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#5-results">5. Results</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#performance-metrics">Performance Metrics</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#visuals">Visuals</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#6-discussion">6. Discussion</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#analysis">Analysis</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#limitations">Limitations</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#comparisons">Comparisons</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#7-conclusion">7. Conclusion</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#summary">Summary</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#future-work">Future Work</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#8-references">8. References</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#9-appendices">9. Appendices</a>
      </li></ul>

  
  



    












  </div>
  </nav>


  <article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]">
    <main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12">

      

      <h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Deep Learning with PyTorch : Generative Adversarial Network</h1>

      <div class="mt-4 mb-16">
      <div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class="mr-1">Jun 27, 2024</span>
        

        
        <span class="mx-1">Â·</span>
        <span class="mx-1">
          14 min read
        </span>
        
        </div>

        <div class="mt-3">
          




<div class="">
  
  








  






  
  
    
  
<a class="hb-attachment-link hb-attachment-large" href="https://colab.research.google.com/drive/1zEnKZ4R0hqSYMJ8P2VO_X_NWAOmmH_W_?usp=sharing" target="_blank" rel="noopener">
  <svg style="height: 1em" class='inline-block' xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M17.25 6.75L22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5-3l-4.5 16.5"/></svg>
  Code
</a>














</div>


        </div>
      </div>



      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      <div class="article-header article-container featured-image-wrapper mt-4 mb-16" style="max-width: 720px; max-height: 314px;">
        <div style="position: relative">
          <img src="/project/gnn/featured_hu07e6bd59ff081afe1e1a1d299bc95a00_74713_6edb1c15975022d51a63686bc0a163d9.webp" width="720" height="314" alt="" class="featured-image">
          
        </div>
      </div>
      

      
      

      <div class="prose prose-slate lg:prose-xl dark:prose-invert">
        <h2 id="1-introduction">1. Introduction</h2>
<h3 id="background">Background</h3>
<p style="text-align: justify;">
Generative Adversarial Networks (GANs) have emerged as a groundbreaking development in the field of machine learning since their introduction by Ian Goodfellow and colleagues in 2014. GANs consist of two competing neural networks, known as the generator and the discriminator, that engage in a dynamic adversarial process. The generator creates synthetic data samples that mimic real data, while the discriminator evaluates these samples against actual data, providing feedback to the generator. This competition drives the generator to produce increasingly realistic data, making GANs exceptionally powerful for tasks such as image generation, data augmentation, and creating realistic simulations.
<p style="text-align: justify;">
The significance of GANs extends beyond academic interest, influencing practical applications across various domains. In computer vision, GANs have been utilized for image super-resolution, inpainting, and style transfer. In healthcare, GANs assist in generating synthetic medical data to augment training datasets, thereby enhancing diagnostic models. GANs also contribute to advancements in natural language processing by generating text and improving translation systems. The versatility and potential of GANs underscore their importance in advancing artificial intelligence and machine learning.
<h3 id="objectives">Objectives</h3>
<p style="text-align: justify;">
The primary objective of this project is to build a GAN using PyTorch to generate realistic images from the MNIST dataset. Specific goals include:
1. Understanding and implementing the basic architecture of GANs.
2. Training the GAN model on the MNIST dataset.
3. Evaluating the performance of the GAN and generating new, unseen data samples.
<h3 id="research-questions">Research Questions</h3>
<ol>
<li>How effectively can a GAN generate realistic images from the MNIST dataset?</li>
<li>What are the challenges faced during the training of a GAN?</li>
<li>How can the performance of the GAN be measured and improved?</li>
</ol>
<h2 id="2-literature-review">2. Literature Review</h2>
<h3 id="review-related-work">Review Related Work</h3>
<p style="text-align: justify;">
Generative Adversarial Networks (GANs) have been a focal point of research since their inception, leading to numerous advancements and variations. The original GAN model proposed by Goodfellow et al. (2014) faced challenges such as training instability and mode collapse. Subsequent research has aimed to address these issues through various modifications and improvements.
<p style="text-align: justify;">
One notable advancement is the Deep Convolutional GAN (DCGAN) introduced by Radford, Metz, and Chintala (2015). DCGANs leverage convolutional layers to improve the stability and quality of generated images, particularly in tasks involving image synthesis. The introduction of convolutional layers allowed for deeper architectures and more complex representations, significantly enhancing the capability of GANs in generating high-resolution images.
<p style="text-align: justify;">
Another significant development is the Wasserstein GAN (WGAN) proposed by Arjovsky, Chintala, and Bottou (2017). WGAN addresses the issue of training stability by using the Earth Moverâ€™s distance (or Wasserstein distance) as a metric, which provides smoother gradients compared to the original GAN formulation. This approach mitigates mode collapse and improves the convergence behavior during training.
<p style="text-align: justify;">
Conditional GANs (CGANs), introduced by Mirza and Osindero (2014), extend the GAN framework by conditioning both the generator and discriminator on additional information such as class labels. This allows for more controlled and specific generation of data, enabling applications in tasks that require generating data with particular attributes or categories.
<h3 id="identify-gaps">Identify Gaps</h3>
<p style="text-align: justify;">
Despite significant advancements, several challenges persist in the effective training and application of GANs. One major challenge is the instability of GAN training, which can result in the generator producing poor-quality or repetitive samples. Mode collapse, where the generator produces a limited variety of outputs, remains a critical issue. Additionally, GANs are highly sensitive to hyperparameter settings, requiring careful tuning to achieve optimal performance.
<p style="text-align: justify;">
This project aims to explore these challenges within the context of the MNIST dataset. By implementing and training a GAN using PyTorch, this work seeks to contribute insights into effective GAN training practices and potential solutions to common problems such as training instability and mode collapse. The insights gained from this project could inform future research and applications of GANs in more complex and diverse datasets.
<h2 id="3-methodology">3. Methodology</h2>
<h4 id="architecture-and-configuration">Architecture and Configuration</h4>
<p style="text-align: justify;">
1. Data Preparation: The MNIST dataset, consisting of grayscale images of handwritten digits, is used for training. Images are augmented through random rotations to enhance model robustness.
<p style="text-align: justify;">
2. Network Design:
    - Discriminator: Utilizes three convolutional layers with batch normalization and LeakyReLU activation functions to distinguish between real and fake images. The final layer outputs a single value indicating the probability of an image being real.
    - Generator: Features four transposed convolutional layers to upsample random noise into images resembling the MNIST dataset. Batch normalization and ReLU activation functions are applied, with the final layer using Tanh activation to ensure output image values are in the range [-1, 1].
Initialization and Optimization:
<p style="text-align: justify;">
3. Network weights are initialized using a normal distribution to stabilize training. The Discriminator and Generator are optimized using the Adam optimizer with specific learning rates and beta values.
4. Loss Functions: Binary Cross-Entropy with Logits Loss is employed to compute the loss for both real and fake images, guiding the networks in distinguishing genuine data from generated data.
<p style="text-align: justify;">
5. Training Loop:The GAN is trained over multiple epochs, with losses for both Discriminator and Generator computed and accumulated to monitor and guide the training process.
<p>This project aims to provide insights into the practical implementation of GANs using PyTorch, emphasizing key aspects such as network architecture, data handling, and optimization techniques. The result is a trained GAN capable of generating realistic handwritten digit images from random noise.</p>
<p><strong>Setting Up the Environment</strong></p>
<p style="text-align: justify;">
Before diving into building a Generative Adversarial Network (GAN), itâ€™s essential to set up the development environment. This includes installing necessary libraries and frameworks that will be used throughout the project and configuration parameters needed for training our Generative Adversarial Network (GAN).
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
</span></span></code></pre></div><p><strong>Configurations</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="c1">#image = image.to(device)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span> <span class="c1"># trianloader, training loop</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">noise_dim</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># generator model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># optimizer parameters</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0002</span>
</span></span><span class="line"><span class="cl"><span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl"><span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.99</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training variables</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
</span></span></code></pre></div><h3 id="data-preparation-and-augmentation">Data Preparation and Augmentation</h3>
<p style="text-align: justify;">
With the environment set up and essential libraries imported, and configurations, we are now ready to move on to loading our dataset and defining the architecture of our GAN. we will be loading and preparing the MNIST dataset, which contains images of handwritten digits ranging from 0 to 9. We will use the torchvision library to download the dataset and apply necessary transformations to the images. Specifically, we'll augment the images with random rotations to introduce variability, which helps the model generalize better. Finally, we'll visualize one of the images from the dataset to ensure that our data is loaded and processed correctly.
<p><strong>Data Description</strong></p>
<p style="text-align: justify;">
The MNIST dataset consists of 60,000 training images and 10,000 testing images of handwritten digits, each of size 28x28 pixels. The dataset is preprocessed using the following steps:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_augs</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">T</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">((</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">+</span><span class="mi">20</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">    <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;MNIST/&#39;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_augs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">images</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">trainset</span><span class="p">[</span><span class="mi">8900</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Total images in trainset:&#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">))</span>
</span></span></code></pre></div><p><strong>Load Dataset Into Batches</strong></p>
<p style="text-align: justify;">
With the MNIST dataset successfully loaded and visualized, we now have our data ready for training. The next steps will involve organizing this data into batches and setting up data loaders, which will streamline the training process by feeding the data into the model efficiently.
<p style="text-align: justify;">
Weâ€™ll use PyTorchâ€™s DataLoader to batch and shuffle the data, ensuring efficient and randomized input during training. This section also includes a custom function, show_tensor_images, which will help us visualize a grid of images from a batch, allowing us to inspect the input data that our GAN will learn from.
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">trainloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Total number od batches in trainloader : &#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">trainloader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataiter</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># &#39;show_tensor_images&#39; : function is used to plot some of images from the batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">show_tensor_images</span><span class="p">(</span><span class="n">tensor_img</span><span class="p">,</span> <span class="n">num_images</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="n">unflat_img</span> <span class="o">=</span> <span class="n">tensor_img</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">img_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">unflat_img</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">show_tensor_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">num_images</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
</span></span></code></pre></div><p style="text-align: justify;">
This step ensures that our data is correctly formatted and ready for the training loop. Next will focus on building the architecture of our GAN, starting with the Discriminator and Generator networks. These networks will be trained using the batched data weâ€™ve just prepared, moving us closer to our goal of generating realistic handwritten digit images.
<h3 id="model-architecture">Model Architecture</h3>
<h4 id="discriminator-network">Discriminator Network</h4>
<p>The Discriminator network is a binary classifier that distinguishes between real and fake images. Its architecture is as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">Network : Discriminator
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">input : (bs, 1, 28, 28)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |                                                                                               ---- SUMMARY ----
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">Conv2d( in_channels = 1, out_channels = 16, kernel_size = (3,3), stride = 2)                           #(bs, 16, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 16, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">LeakyReLU()                                                                                            #(bs, 16, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">Conv2d( in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 2)                          #(bs, 32, 5, 5)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 32, 5, 5)
</span></span></span><span class="line"><span class="cl"><span class="s1">LeakyReLU()                                                                                            #(bs, 32, 5, 5)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">Conv2d( in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 2)                          #(bs, 64, 1, 1)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 64, 1, 1)
</span></span></span><span class="line"><span class="cl"><span class="s1">LeakyReLU()                                                                                            #(bs, 64, 1, 1)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">Flatten()                                                                                              #(bs, 64)
</span></span></span><span class="line"><span class="cl"><span class="s1">Linear(in_features = 64, out_features = 1)                                                             #(bs, 1)
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_disc_block</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">images</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_1</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_2</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_3</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x5</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">D</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">D</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">summary</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">(),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
</span></span></code></pre></div><h4 id="generator-network">Generator Network</h4>
<p>The Generator network creates new images from random noise. Its architecture is as follows:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">Network : Generator
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">z_dim = 64
</span></span></span><span class="line"><span class="cl"><span class="s1">input : (bs,z_dim)
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      | Reshape
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">input : (bs, channel, height, width) -&gt; (bs, z_dim , 1 , 1)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |                                                                                               ---- SUMMARY ----
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">ConvTranspose2d( in_channels = z_dim, out_channels = 256, kernel_size = (3,3), stride = 2)             #(bs, 256, 3, 3)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 256, 3, 3)
</span></span></span><span class="line"><span class="cl"><span class="s1">ReLU()                                                                                                 #(bs, 256, 3, 3)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">ConvTranspose2d( in_channels = 256, out_channels = 128, kernel_size = (4,4), stride = 1)               #(bs, 128, 6, 6)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 128, 6, 6)
</span></span></span><span class="line"><span class="cl"><span class="s1">ReLU()                                                                                                 #(bs, 128, 6, 6)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">ConvTranspose2d( in_channels = 128, out_channels = 64, kernel_size = (3,3), stride = 2)                #(bs, 64, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">BatchNorm2d()                                                                                          #(bs, 64, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">ReLU()                                                                                                 #(bs, 64, 13, 13)
</span></span></span><span class="line"><span class="cl"><span class="s1">      |
</span></span></span><span class="line"><span class="cl"><span class="s1">      V
</span></span></span><span class="line"><span class="cl"><span class="s1">ConvTranspose2d( in_channels = 64, out_channels = 1, kernel_size = (4,4), stride = 2)                  #(bs, 1, 28, 28)
</span></span></span><span class="line"><span class="cl"><span class="s1">Tanh()                                                                                                 #(bs, 1, 28, 28)
</span></span></span><span class="line"><span class="cl"><span class="s1">
</span></span></span><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39;</span> 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_gen_block</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">final_block</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">final_block</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">          <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">          <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r_noise_vec</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, noise_dim) -&gt; (bs, noise_dim, 1, 1)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">r_noise_vec</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_2</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_3</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_4</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x4</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">G</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">noise_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">G</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">summary</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">noise_dim</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Replace Random initialized weights to Normal weights</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">weights_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weights_init</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">G</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weights_init</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="create-loss-function-and-load-optimizer">Create Loss Function and Load Optimizer</h4>
<p style="text-align: justify;">
Now that we have defined our Generator and Discriminator models, it's time to set up the loss functions and optimizers that will guide their training. The Discriminator will use binary cross-entropy loss with logits (BCEWithLogitsLoss) to measure its performance. Specifically, when given real images, the Discriminator's loss function will compare its predictions to a ground truth of all ones, and when given fake images, it will compare to all zeros. These loss functions will help the Discriminator learn to distinguish between real and generated images effectively. Weâ€™ll also define optimizers for both models using Adam optimization, which is well-suited for deep learning tasks due to its adaptive learning rate.
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">real_loss</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fake_loss</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">loss</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">D_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">G_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">))</span>
</span></span></code></pre></div><p style="text-align: justify;">
With the loss functions and optimizers defined, we are now ready to begin the training process. The loss functions will guide the Discriminator in distinguishing between real and fake images while helping the Generator learn to produce more realistic images. The Adam optimizer, with its carefully chosen hyperparameters, will ensure that both networks update their weights efficiently during training. In the next step, we will set up the training loop, where these components will work together to iteratively improve the Generatorâ€™s ability to fool the Discriminator and, ultimately, generate convincing images.
<h4 id="training-loop">Training Loop</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Training Loop</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="c1"># Initialize total losses for the epoch</span>
</span></span><span class="line"><span class="cl">  <span class="n">total_d_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">  <span class="n">total_g_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># Iterate over each batch in the training loader</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">real_img</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Move real images to the appropriate device</span>
</span></span><span class="line"><span class="cl">    <span class="n">real_img</span> <span class="o">=</span> <span class="n">real_img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Generate random noise for the Generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">noise_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --------------------- Train the Discriminator ---------------------</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Zero the gradients for the Discriminator</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Generate fake images using the Generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">fake_img</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Get Discriminator&#39;s prediction for fake images</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_pred</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">fake_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Calculate loss for fake images</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_fake_loss</span> <span class="o">=</span> <span class="n">fake_loss</span><span class="p">(</span><span class="n">D_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Get Discriminator&#39;s prediction for real images</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_pred</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">real_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Calculate loss for real images</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_real_loss</span> <span class="o">=</span> <span class="n">real_loss</span><span class="p">(</span><span class="n">D_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Compute the average loss for the Discriminator</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">D_fake_loss</span> <span class="o">+</span> <span class="n">D_real_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Accumulate Discriminator&#39;s loss for the epoch</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_d_loss</span> <span class="o">+=</span> <span class="n">D_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Backpropagate the loss and update Discriminator&#39;s weights</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># --------------------- Train the Generator ---------------------</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Zero the gradients for the Generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">G_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Generate new random noise for the Generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">noise_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Generate fake images using the Generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">fake_img</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Get Discriminator&#39;s prediction for fake images</span>
</span></span><span class="line"><span class="cl">    <span class="n">D_pred</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">fake_img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Calculate Generator&#39;s loss based on Discriminator&#39;s predictions</span>
</span></span><span class="line"><span class="cl">    <span class="n">G_loss</span> <span class="o">=</span> <span class="n">real_loss</span><span class="p">(</span><span class="n">D_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Accumulate Generator&#39;s loss for the epoch</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_g_loss</span> <span class="o">+=</span> <span class="n">G_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Backpropagate the loss and update Generator&#39;s weights</span>
</span></span><span class="line"><span class="cl">    <span class="n">G_l</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Run after training is completed.</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Now you can use Generator Network to generate handwritten images</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">noise_dim</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">generated_image</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">show_tensor_images</span><span class="p">(</span><span class="n">generated_image</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="4-experimental-setup">4. Experimental Setup</h2>
<h3 id="environment">Environment</h3>
<ul>
<li><strong>Hardware:</strong> NVIDIA GPU (e.g., GTX 1080 Ti)</li>
<li><strong>Software:</strong> PyTorch 1.8.0, Python 3.8</li>
</ul>
<h3 id="parameters">Parameters</h3>
<ul>
<li><strong>Learning Rate:</strong> 0.0002</li>
<li><strong>Batch Size:</strong> 128</li>
<li><strong>Epochs:</strong> 20</li>
<li><strong>Noise Dimension:</strong> 64</li>
</ul>
<h2 id="5-results">5. Results</h2>
<h3 id="performance-metrics">Performance Metrics</h3>
<p>The performance of the GAN is evaluated based on the discriminator and generator loss curves over the epochs.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Assuming loss curves are plotted and saved</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">d_loss_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Discriminator Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">g_loss_history</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Generator Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="visuals">Visuals</h3>
<p>The following images are generated by the GAN at various training epochs:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Function to visualize images generated at different epochs</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">show_tensor_images</span><span class="p">(</span><span class="n">tensor_img</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">    <span class="n">unflat_img</span> <span class="o">=</span> <span class="n">tensor_img</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">img_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">unflat_img</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">show_tensor_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</span></span></code></pre></div><ol>
<li><strong>Generator Performance</strong>:</li>
</ol>
<p style="text-align: justify;">
   - The Generator progressively improved its ability to produce handwritten digit images that visually resemble those in the MNIST dataset. Early generated images displayed noticeable artifacts and lacked clarity, but as training progressed, the images became more coherent and closer to actual MNIST digits.
<ol start="2">
<li><strong>Discriminator Performance</strong>:</li>
</ol>
<p style="text-align: justify;">
   - The Discriminator effectively learned to differentiate between real MNIST images and those generated by the Generator. Initially, the Discriminator showed high accuracy in classifying real versus fake images, but as the Generator improved, the Discriminator's accuracy fluctuated, reflecting the adversarial nature of the training process.
<ol start="3">
<li><strong>Loss Metrics</strong>:</li>
</ol>
<p style="text-align: justify;">
   - Loss values for both the Generator and Discriminator were monitored throughout the training process. The Discriminator's loss decreased over time, indicating improved classification capabilities, while the Generator's loss showed a downward trend as it generated more realistic images.
<ol start="4">
<li><strong>Visual Output</strong>:</li>
</ol>
<p style="text-align: justify;">
   - Images generated by the trained Generator were visually inspected at various stages of training. The final generated images displayed significant improvement in quality, with well-defined handwritten digits that closely resembled those in the MNIST dataset.
<h2 id="6-discussion">6. Discussion</h2>
<h3 id="analysis">Analysis</h3>
<p style="text-align: justify;">
The generated images demonstrate the GAN's capability to learn and produce realistic handwritten digits. The loss curves indicate the model's training progression and stability over the epochs.
<h3 id="limitations">Limitations</h3>
<p style="text-align: justify;">
- Training instability due to adversarial nature
- Mode collapse where the generator produces limited varieties of images
- Sensitivity to hyperparameters such as learning rate and batch size
<h3 id="comparisons">Comparisons</h3>
<p style="text-align: justify;">
The results can be compared with other GAN variations and methods in the literature, such as DCGAN and Wasserstein GAN, to evaluate improvements in stability and image quality.
<h2 id="7-conclusion">7. Conclusion</h2>
<h3 id="summary">Summary</h3>
<p style="text-align: justify;">
This project successfully implemented a GAN using PyTorch to generate realistic MNIST digits. The results highlight the potential and challenges of GANs in image generation tasks. The GAN demonstrated the ability to generate high-quality handwritten digit images after sufficient training.
<p style="text-align: justify;">
Overall, this project provides a foundational understanding of GANs and demonstrates their capability to generate realistic data, paving the way for further exploration and advancements in generative modeling.
<h3 id="future-work">Future Work</h3>
<ul>
<li>Experiment with advanced GAN architectures such as DCGAN and CGAN.</li>
<li>Explore different datasets beyond MNIST.</li>
<li>Implement techniques to improve training stability and image quality, such as using Wasserstein loss or spectral normalization.</li>
</ul>
<h2 id="8-references">8. References</h2>
<ul>
<li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., &hellip; &amp; Bengio, Y. (2014). Generative adversarial nets. Advances in neural information processing systems, 27.</li>
<li>Radford, A., Metz, L., &amp; Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434.</li>
<li>Arjovsky, M., Chintala, S., &amp; Bottou, L. (2017). Wasserstein gan. arXiv preprint arXiv:1701.07875.</li>
</ul>
<h2 id="9-appendices">9. Appendices</h2>
<h3 id="heading"></h3>
<p>Code Listings
Key code snippets are provided throughout the document. For the complete code, please refer to the repository: <a href="#">GitHub Repository Link</a></p>

      </div>

      
  <time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime="2024-06-27T22:52:51.000Z">
    <span>Last updated on</span>
    Jun 27, 2024</time>

      <div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5">
        
        <div class="max-w-prose print:hidden">
  
  

  

<div class="flex justify-center">
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/pytorch/">PyTorch</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/gan/">GAN</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/deep-learning/">Deep Learning</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/neural-networks/">Neural Networks</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/mnist/">MNIST</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/image-generation/">Image Generation</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/data-science/">Data Science</a>
  
</div>


  
<section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://twitter.com/intent/tweet?url=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fgnn%2F&amp;text=Deep&#43;Learning&#43;with&#43;PyTorch&#43;%3A&#43;Generative&#43;Adversarial&#43;Network"
    title="X"
    aria-label="X"
    id="share-link-x"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fgnn%2F&amp;t=Deep&#43;Learning&#43;with&#43;PyTorch&#43;%3A&#43;Generative&#43;Adversarial&#43;Network"
    title="Facebook"
    aria-label="Facebook"
    id="share-link-facebook"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55 0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
  </a>
  

  
  
  
  
  
  
    
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="mailto:?subject=Deep%20Learning%20with%20PyTorch%20%3A%20Generative%20Adversarial%20Network&amp;body=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fgnn%2F"
    title="Email"
    aria-label="Email"
    id="share-link-email"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5 0 1 1-9 0a4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fgnn%2F&amp;title=Deep&#43;Learning&#43;with&#43;PyTorch&#43;%3A&#43;Generative&#43;Adversarial&#43;Network"
    title="LinkedIn"
    aria-label="LinkedIn"
    id="share-link-linkedin"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="whatsapp://send?text=Deep&#43;Learning&#43;with&#43;PyTorch&#43;%3A&#43;Generative&#43;Adversarial&#43;Network%20http%3A%2F%2Flocalhost%3A1313%2Fproject%2Fgnn%2F"
    title="WhatsApp"
    aria-label="WhatsApp"
    id="share-link-whatsapp"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256" fill="currentColor"><path d="m187.58 144.84-32-16a8 8 0 0 0-8 .5l-14.69 9.8a40.55 40.55 0 0 1-16-16l9.8-14.69a8 8 0 0 0 .5-8l-16-32A8 8 0 0 0 104 64a40 40 0 0 0-40 40 88.1 88.1 0 0 0 88 88 40 40 0 0 0 40-40 8 8 0 0 0-4.42-7.16ZM152 176a72.08 72.08 0 0 1-72-72 24 24 0 0 1 19.29-23.54l11.48 23L101 118a8 8 0 0 0-.73 7.51 56.47 56.47 0 0 0 30.15 30.15A8 8 0 0 0 138 155l14.61-9.74 23 11.48A24 24 0 0 1 152 176ZM128 24a104 104 0 0 0-91.82 152.88l-11.35 34.05a16 16 0 0 0 20.24 20.24l34.05-11.35A104 104 0 1 0 128 24Zm0 192a87.87 87.87 0 0 1-44.06-11.81 8 8 0 0 0-6.54-.67L40 216l12.47-37.4a8 8 0 0 0-.66-6.54A88 88 0 1 1 128 216Z"/></svg>
  </a>
  
</section>


  








  
  



  
  
  
    
  
  
  

<div class="flex pt-12 pb-4">
  
  
  <img
    class="mr-4 h-24 w-24 rounded-full"
    width="96"
    height="96"
    alt=""
  src="/author/Avatar_1_hue88d0c5568a0d2dd097d18664ac72c5a_44184_192x192_fill_q80_lanczos_center.jpg"
  loading="lazy"
  />
  
  <div class="place-self-center">
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Authors
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      <a href="http://localhost:1313/" class="no-underline">
      
      </a>
    </div>

    
    <div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">
    Data Scientist
    </div>
    


    

    <div class="text-2xl sm:text-lg pt-1">

      
<div class="flex flex-wrap text-neutral-500 dark:text-neutral-300">
  
    
    
    
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="mailto:israelzemedkun@gmail.com"
      
      aria-label="At-Symbol"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5 0 1 1-9 0a4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://www.instagram.com/israelzemedkun//"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Instagram"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15 15"><path fill="currentColor" fill-rule="evenodd" d="M12.91 12.909c.326-.327.582-.72.749-1.151c.16-.414.27-.886.302-1.578c.032-.693.04-.915.04-2.68c0-1.765-.008-1.987-.04-2.68c-.032-.692-.142-1.164-.302-1.578a3.185 3.185 0 0 0-.75-1.151a3.187 3.187 0 0 0-1.151-.75c-.414-.16-.886-.27-1.578-.302C9.487 1.007 9.265 1 7.5 1c-1.765 0-1.987.007-2.68.04c-.692.03-1.164.14-1.578.301a3.2 3.2 0 0 0-1.151.75a3.2 3.2 0 0 0-.75 1.151c-.16.414-.27.886-.302 1.578C1.007 5.513 1 5.735 1 7.5c0 1.765.007 1.987.04 2.68c.03.692.14 1.164.301 1.578c.164.434.42.826.75 1.151c.325.33.718.586 1.151.75c.414.16.886.27 1.578.302c.693.031.915.039 2.68.039c1.765 0 1.987-.008 2.68-.04c.692-.03 1.164-.14 1.578-.301a3.323 3.323 0 0 0 1.151-.75ZM2 6.735v1.53c-.002.821-.002 1.034.02 1.5c.026.586.058 1.016.156 1.34c.094.312.199.63.543 1.012c.344.383.675.556 1.097.684c.423.127.954.154 1.415.175c.522.024.73.024 1.826.024H8.24c.842.001 1.054.002 1.526-.02c.585-.027 1.015-.059 1.34-.156c.311-.094.629-.2 1.011-.543c.383-.344.556-.676.684-1.098c.127-.422.155-.953.176-1.414C13 9.247 13 9.04 13 7.947v-.89c0-1.096 0-1.303-.023-1.826c-.021-.461-.049-.992-.176-1.414c-.127-.423-.3-.754-.684-1.098c-.383-.344-.7-.449-1.011-.543c-.325-.097-.755-.13-1.34-.156A27.29 27.29 0 0 0 8.24 2H7.057c-1.096 0-1.304 0-1.826.023c-.461.021-.992.049-1.415.176c-.422.128-.753.301-1.097.684c-.344.383-.45.7-.543 1.012c-.098.324-.13.754-.156 1.34c-.022.466-.022.679-.02 1.5ZM7.5 5.25a2.25 2.25 0 1 0 0 4.5a2.25 2.25 0 0 0 0-4.5ZM4.25 7.5a3.25 3.25 0 1 1 6.5 0a3.25 3.25 0 0 1-6.5 0Zm6.72-2.72a.75.75 0 1 0 0-1.5a.75.75 0 0 0 0 1.5Z" clip-rule="evenodd"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://github.com/Israelzemedkun"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Github"
    ><svg style="height: 1em;" fill="currentColor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://www.linkedin.com/in/israel-gebre-255a0b9a"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Linkedin"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
  
</div>



    </div>
  </div>
</div>







  
  
    
    
    
      
      
    
<div class="pt-1 no-prose w-full">
  <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
  <div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2">
    <div class="">
      
        <a class="group flex no-underline" href="/project/preprint/">
          <span
            class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline rtl:hidden">&larr;</span></span>
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >Mapping Teak Tree Plantations</span>
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                Aug 7, 2024
              
            </span>
          </span>
        </a>
      
    </div>
    <div class="">
      
        <a class="group flex text-right no-underline" href="/project/streamlit-dashboard/">
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >Motor Vehicle Collisions in New York City Dashboard Project</span
            >
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                Apr 27, 2024
              
            </span>
          </span>
          <span
            class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline">&rarr;</span></span>
        </a>
      
    </div>
  </div>
</div>



  


  



</div>

      </div>

    </main>
  </article>
</div>

    </div>
    <div class="page-footer">
      <footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200">

  












  
  
  
  
  














  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by text-center">
    Â© 2024 Israel.
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by text-center">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> â€” the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>

</footer>

    </div>

    
    











  </body>
</html>
